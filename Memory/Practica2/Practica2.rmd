---
output:
  pdf_document:
    fig_caption: yes
    citation_package: natbib
    highlight: espresso
    includes:
      in_header: mystyles.sty
bibliography: references.bib
biblio-style: plain
toc: no
fontsize: 10pt
geometry: a4paper, top=2.5cm, bottom=2.5cm, left=3cm, right=3cm
lang: es-ES
linestretch: 1
csl: ieee.csl

---
<!--
Highlights: default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, null
-->
<!--
csl: ieee.csl
mainfont: Arial
monofont: Source Code Pro

abstract: Resumen
  
(Cosas que puedo añadir a la cabecera)
-->

<!--

Añadir imagenes:

\begin{figure}[h]
\centering
\includegraphics[width=10 cm]{./images/1_1.png}
\caption{Instalación de phoronix suite.\label{fig:phinst}}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=10 cm]{./images/1_2.png}
\caption{Lista de test disponibles.\label{fig:phtests}}
\end{figure}

-->

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 
%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------

\textsc{\LARGE METAHEURíSTICAS }\\[0.3cm] % Name of your university/college
\textsc{\LARGE Práctica 1 }\\[0.3cm]
\textsc{\Large Universidad de Granada }\\[0.3cm]
\textsc{\Large CURSO 2016/2017}\\[0.5cm] % Major heading such as course name
 % Minor heading such as course title

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[0.4cm]
{ \huge \bfseries Enfriamiento Simulado, Búsqueda Local Reiterada y Evolución Diferencial para el Problema del Aprendizaje de Pesos en Características }\\[0.03cm] % Title of your document
\HRule \\[1.5cm]

 
%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Contenido}\\
Enfriamiento Simulado \\Búsqueda Local Reiterada\\Evolución Diferencial
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Autor:} \\
Juan Luis Suárez Díaz\\77148642-H\\\url{jlsuarezdiaz@correo.ugr.es}\\GRUPO 2 (VIERNES)\\Cuarto Curso del DGIIM
\end{flushright}
\end{minipage}\\[1cm]

% If you don't want a supervisor, uncomment the two lines below and remove the section above
%\Large \emph{Author:}\\
%John \textsc{Smith}\\[3cm] % Your name

%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------

{\large \today}\\[1cm] % Date, change the \today to a set date if you want to be precise

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------


\includegraphics[width = 5 cm]{./images/logo.jpg}\\[1cm] % Include a department/university logo - this will require the graphicx package

 
%----------------------------------------------------------------------------------------

\vfill % Fill the rest of the page with whitespace

\end{titlepage}

\clearpage

\tableofcontents

\clearpage

# Descripción del problema

Estamos ante un problema de aprendizaje automático, en concreto un problema de clasificación, en el que se pretende optimizar el rendimiento del clasificador 1NN. Este clasificador, dada una muestra de datos y un nuevo dato a clasificar, obtiene la clase para el nuevo dato como aquella correspondiente a la del dato más cercano en la muestra. Con esta descripción, el clasificador obtendrá el vecino más cercano ponderando en la misma medida todas las características de los datos que manejamos, lo que en principio puede darnos peores resultados, puesto que es posible que no todas las características consideradas tengan la misma relevancia a la hora de realizar la clasificación.

Mediante el Aprendizaje de Pesos en Características se pretende, a partir de la muestra de entrenamiento, obtener un vector de pesos asociado al conjunto de características, de forma que la distancia para obtener el vecino más cercano se calcule ponderando cada componente con el peso obtenido. Si el aprendizaje es efectivo, el vector de pesos nos permitirá aumentar la tasa de acierto a la hora de clasificar nuevos datos. En las siguientes secciones estudiaremos distintas heurísticas con las que afrontar este problema y veremos en qué medida permiten mejorar el rendimiento del clasificador 1NN.


\clearpage

# Consideraciones comunes

## Esquemas de representación

Trabajaremos en concreto con 3 conjuntos de datos: `sonar`, `Wdbc` y `Spambase`. Estos conjuntos están formados por un conjunto de ejemplos, cada uno con un número fijo de características y una clase asociada. Los ejemplos junto con sus características los representaremos en una matriz, donde cada fila es un ejemplo y cada columna una característica. Además, para dar igual importancia a todos los atributos, la matriz estará normalizada por columnas (características), utilizando como criterio de normalización los valores máximo y mínimo encontrados para cada característica en la matriz.

Más adelante tendremos que hacer particiones de los datos, de forma que en cada partición haya un subconjunto de ejemplos. Para representar las particiones utilizaremos un vector de índices `v`, de forma que, si `p` es la partición considerada y `m` es la matriz de ejemplos del problema, se tiene que `p[i] = m[v[i]]`, es decir, el ejemplo i-ésimo en la partición es el ejemplo en el problema dado por el elemento i-ésimo del vector de índices.

Las soluciones con las que trabajaremos serán vectores reales de pesos, de tamaño el número de características del problema (las columnas de la matriz). Las soluciones tomarán siempre valores en $[0,1]$.

## Función objetivo

Para evaluar el rendimiento del clasificador 1NN con un algoritmo determinado, utilizaremos la técnica de validación cruzada 5-Fold. Para ello, haremos 5 particiones distintas de los datos, y para cada partición, aprenderemos el vector de pesos con el contenido de su partición y lo evaluaremos con las restantes. El valor de rendimiento promedio será la media de estas 5 evaluaciones.

<!--
\begin{algorithm}
\caption{Validación cruzada}
\label{alg:5x2cv}
\begin{algorithmic}
  \FOR{ i=1 \TO 5}
      \STATE $solucion1 = algoritmo(particion[i][1])$
      \STATE $fitness1[i] = f\_objetivo(particion[i][2], solucion)$
      
      \STATE $solucion2 = algoritmo(particion[i][2])$
      \STATE $fitness2[i] = f\_objetivo(particion[i][1], solucion)$
  \ENDFOR
  \RETURN media(fitness1, fitness2)
\end{algorithmic}
\end{algorithm}
-->


$\text{   }$

~~~ruby

for i from 1 to 5
    solucion = algoritmo(particion[i])
    fitness[i] = f_objetivo(datos-particion[i], solucion)
    
end

return media(fitness)
~~~

$\text{   }$

Para evaluar una solución sobre la partición de entrenamiento, seguiremos dos criterios: por un lado, obtendremos el porcentaje de los datos que quedan bien clasificados al evaluarlo sobre el resto de la partición. Por otro lado, se considerará que una solución es mejor cuanto mayor número de características haya conseguido eliminar, entendiendo por eliminable a cada característica para la que el peso obtenido sea cercano a cero (concretamente, menor que 0.1). Ambos criterios ponderarán en la misma medida dentro de la función objetivo. Como consecuencia del criterio de reducción, al calcular la distancia en el criterio de clasificación tampoco se tendrán en cuenta los atributos con pesos menores que 0.1.

La tasa de clasificación de una solución sobre una partición de entrenamiento, se realizará aplicando el clasificador sobre cada dato de la partición y viendo si la clase obtenida por el clasificador coincide con la clase del dato. Para evitar que el vecino más cercano proporcionado por el clasificador sea el mismo dato, el dato a clasificar se aparta de la muestra, siguiendo el procedimiento *Leave One Out*. El porcentaje de aciertos será la medida de evaluación sobre la partición. 




$\text{   }$

~~~ruby

def tasa_clas(particion, solucion)
    aciertos = 0
    
    for dato in particion
      c = clasificar_1NN(particion, solucion, dato)
      if c = dato.clase
          aciertos++
      end
    end
    
    return (100 * aciertos)/particion.tamaño
end

~~~

$\text{   }$


Finalmente, se describe el pseudocódigo del clasificador 1NN (para un dato en la partición de entrenamiento con *Leave One Out*).


$\text{   }$

~~~ruby
def clasificar_1NN(particion,solucion,dato)
    # Para evitar asignar el dato a clasificar
    if particion.primero != dato then clase_min = particion.primero.clase
    else clase_min = particion.segundo.clase
    
    if particion.primero != dato then dist_min = sqDist(particion.primero, dato)
    else dist_min = sqDist(particion.segundo, dato)
    
    for dato_test in particion
        if dato_test != dato # Dejamos fuera el dato a clasificar
            if sqDist(dato_test, dato) < dist_min
                clase_min = dato_test.clase
                dist_min = sqDist(dato_test, dato)
            end
        end    
    end
  
    return clase_min
end

# Función distancia euclidea al cuadrado ponderada con los pesos de la solución
def sqDist(dato1, dato2, solucion)
    suma = 0
    for i from 1 to solucion.size
        if solucion[i] >= 0.1  # Considerando la reducción
            suma = suma + solucion[i]*(dato1[i]-dato2[i])^2
        end
    end
end
~~~

$\text{   }$

La tasa de reducción consistirá en contar simplemente los pesos en la solución que valgan menos que 0.1:

$\text{   }$

~~~ruby

def tasa_red(solucion)
    num_reds = 0
    for peso in solucion
        if peso < 0.1 then num_reds++
    end
    return 100 * (num_reds)/solucion.size
end
~~~

$\text{   }$

Finalmente, como ya se ha comentado, el valor final de la función objetivo se obtiene combinando ambas tasas: $f = \alpha\ tasa\_clas + (1-\alpha)tasa\_red$. En este caso las ponderamos igual, es decir, $\alpha = 0,5$.

La evaluación de la partición test se realizará aplicando este mismo procedimiento usando la partición aprendida como el conjunto sobre el que se busca el vecino más cercano. En este caso, la tasa de clasificación se obtendrá sin *Leave One Out*, mientras que evidentemente la tasa de reducción coincidirá con la obtenida durante el aprendizaje.


Un aspecto importante a destacar en la función objetivo que se ha tenido en cuenta durante la implementación es que el orden de eficiencia es de $O(P\times P\times S)$, donde $P$ es el tamaño de la partición y $S$ el tamaño de la solución. Es un orden considerable y la función se llamará gran cantidad de veces a lo largo de los distintos algoritmos, por lo que es bueno considerar cualquier posible mejora de esta. Para ello, en la implementación se ha optado por modificar ligeramente la estructura del algoritmo, sin modificar el resultado. Se ha tenido en cuenta que la función distancia ponderada es simétrica respecto de los datos para una solución prefijada. De esta forma, la modificación considerada para la implementación consiste en la inicialización al principio del algoritmo de una matriz triangular con las distancias entre todos los datos de la partición, y la obtención de las distancias durante la clasificación se reduce a acceder a una posición de la matriz ya creada. Aunque la clase de complejidad sigue siendo la misma, el uso de una matriz solamente triangular para calcular las distancias permite reducir las iteraciones a la mitad.

## Generación de vecinos

Consideraremos que una solución es vecina de una solución si se diferencian en una única componente en un valor que sigue una distribución normal centrada en 0 y con desviación 0.3. De esta forma, para generar un vecino de una solución, dada una componente, le sumaremos un valor extraído de la distribucuón normal anterior. Para cumplir con  las restricciones del problema, si la suma supera el valor 1 o alcanza un valor negativo, se truncará a 1 o a 0, respectivamente.


$\text{   }$

~~~ruby
def mov(solucion,i,sigma)
    solucion[i] = solucion[i] + normal(0,sigma).nuevoNumero()
end
~~~

$\text{   }$


## Generación de soluciones aleatorias

Para generar una solución aleatoria, a cada componente le asignaremos un valor uniformemente distribuido entre 0 y 1.


$\text{   }$

~~~ruby
def solucionAleatoria(problema)
    for i in 1 to problema.numeroAtributos
        solucion[i] = uniforme(0,1).nuevoNumero()
    end
    return solucion
end
~~~

$\text{   }$

## Búsqueda local

Se mantiene el mismo algoritmo de búsqueda local implementado en la práctica anterior. El algoritmo de búsqueda local utilizado sigue el modelo del primer mejor. Con el operador de generación de vecinos indicado previamente se generan nuevas soluciones, y en cuanto una mejora a la solución actual, se actualiza como nueva solución. El procedimiento se repite mientras no se verifique ninguna de las condiciones de parada. En este caso, las condiciones de parada vienen dadas por un número máximo de evaluaciones de la función objetivo, o bien, por un número máximo de vecinos generados sin obtener mejora.

En cuanto a aspectos de implementación, se considera durante todo el proceso una única solución que va siendo modificada, y en caso de que no haya mejora, se devuelve la componente modificada a su estado anterior. Esto mejora la eficiencia al evitar copiar soluciones, aunque el cuello de botella está en la llamada a la función objetivo.

Finalmente, la selección de la componente a modificar de la solución se hace de forma aleatoria, pero recorriendo todas las componentes antes de dar una nueva pasada al vector. Para eso se utiliza una permutación que se va barajando cada vez que se recorre.

El pseudocódigo es el siguiente:

$\text{   }$

~~~ruby
def BusquedaLocal(part_train, solucion, max_evals, max_no_mej)
    num_evals = 0
    no_mejoras = 0
    
    fitness = f_objetivo(part_train,solucion)
    permutacion = [1,...,solucion.size]
    
    # Mientras no condiciones de parada
    while num_evals < max_evals and no_mejoras < max_no_mej 
        shuffle(permutacion)
        for indice in permutacion
            peso_actual = solucion[indice] # Para deshacer la mutación
            mov(solucion,indice,0.3)       # Generamos vecino
            newfit = f_objetivo(part_train,solucion)
            num_evals++             # Nueva evaluación de la función objetivo
            
            if newfit > fit
                 # Hay mejora, actualizamos fitness y resteamos no_mejoras
                fitness = newfit
                no_mejoras = 0
            else
                # No hay mejora, deshacemos la mutación e incrementamos no_mejoras
                solucion[indice] = peso_actual
                no_mejoras++
            end    
        end
    end
    return solucion    
end

~~~

$\text{   }$

\clearpage



# Métodos de búsqueda

## Enfriamiento simulado

El algoritmo de enfriamiento simulado se inspira en los procesos de calentamiento de algunos materiales. En este caso, la aceptación de soluciones depende en gran medida de una variable temperatura. La variable temperatura determinará una probabilidad con la que el algoritmo de exploración podrá aceptar soluciones peores a la actual. Análogamente a su inspiración física, a mayor temperatura, habrá más movimiento y se explorará el espacio de búsqueda con una mayor amplitud. Cuando la temperatura vaya disminuyendo, se intensificará la explotación de las soluciones obtenidas. La generación de nuevas soluciones seguirá el esquema de vecinos habitual, con la novedad del criterio de aceptación basado en la temperatura. El esquema de búsqueda se resume en el siguiente pseudocódigo:


$\text{   }$

~~~ruby

def SimulatedAnnealing(particion)

    inicializarTemperaturas()
    
    best_sol = s = solucionAleatoria()
    fit = best_fit = fitness(particion,s)
    
    while not condicionesParada()
        
        num_neighbours = 0
        num_success = 0
        permutacion = generarPermutacion(s.size())
        
        while num_neighbours < max_neighbours and num_success < max_success 
            
            # Para ir mutando todas las componentes
            if(permutacion.empty()) permutacion = generarPermutacion(s.size())
            rnd = permutacion.extraer()
            
            s_i = s[rnd] # Para deshacer la mutación después sin copiar
            
            s.mov(rnd,0.3) # Generamos vecino
            newfit = fitness(particion,s)
            num_neighbours++
            
            diff = (fit - newfit)/100.0 # Diferencia de costes
            
            # Criterio de aceptación
            # Aceptamos si es mejor, o si es peor según la probabilidad siguiente
            if diff != 0 and (diff < 0 or AleatorioUniforme(0,1) <= exp(-diff/temp))
            
                # Actualizamos
                fit = newfit
                if fit > best_fit # Actualizamos mejor solución si es necesario
                    best_sol = s
                    bestfit = fit
                end
                
                num_success++
            else
              s[rnd] = s_i # Deshacemos mutación
              
            end
        end
        
        enfriar()
    end
    
    return best_sol

~~~

$\text{   }$

El criterio de parada utilizado viene dado por un máximo de evaluaciones de la función objetivo, por una parte, o por otra, que en alguno de los bucles internos (los de temperatura fija) no se haya aceptado ninguna solución, es decir, se llega a una temperatura a la que el algoritmo no se presta a aceptar peores soluciones y tampoco a mejorar por generación de vecinos.

En cuanto a la inicialización de temperaturas, el procedimiento seguido para determinar la temperatura inicial es el siguiente:

\[T_0 = \frac{\mu C(S_0)}{\log(\phi)}\]

Donde se han tomado $\mu = \phi = 0,3$ y $C(S_0)$ es el coste de la solución inicial.

Finalmente, se utiliza el esquema de enfriamiento de Cauchy:

\[T_{k+1} = \frac{T_k}{1+\beta T_k}\]

Donde $\beta = \frac{T_0-T_f}{M T_0 T_f}$ y $M = \frac{max\_evaluaciones}{max\_vecinos}$. El criterio para la llamada al esquema de enfriamiento se basa en un número máximo de vecinos generados $max\_vecinos$ y un número máximo de éxitos (soluciones que son aceptadas por el criterio de la temperatura) $max\_success$, como se mostraba en el pseudocódigo anterior.

## Búsqueda Local Reiterada

El esquema de búsqueda empleado en la búsqueda local reiterada es el siguiente: partimos de una solución inicial optimizada con búsqueda local, y durante repetidas veces a la solución que tenemos le aplicamos una mutación brusca, y a dicha mutación le aplicamos búsqueda local. Nos quedamos con la que tenga un mayor valor de la función objetivo y repetimos el proceso.

$\text{   }$

~~~ruby

def ILS(particion)
    # Solución inicial+BL
    s = solucionAleatoria()
    busquedaLocal(s,particion)
    fit = f_objetivo(particion,s)
    
    while not condicionesParada()
        s' = mutacionBrusca(s)
        busquedaLocal(s',particion)
        newfit = f_objetivo(particion,s')
        
        if newfit > fit
            s = s'
            fit = newfit
        end
    end
    
end
~~~

$\text{   }$

Finalmente, el operador de mutación brusca de la solución consiste en un conjunto de mutaciones simples (la generación de vecinos usual) con una mayor desviación (0.4 en lugar del usual 0.3). El número de mutaciones simples realizado ha sido un 10 \% del total de atributos. A la hora de mutar, se puede optar tanto por seleccionar los atributos completamente al azar como por controlar que no mute siempre el mismo atributo. En la implementación se ha optado por esta segunda opción, utilizando vectores de permutaciones de los atributos.

$\text{   }$

~~~ruby

def mutacionBrusca(solucion)
    s = solucion.copia()

    num_mutaciones = 0.1 * solucion.size
    # Obtenemos los índices a mutar (por cualquiera de los 
    # procedimientos aleatorios indicados previamente)
    indices_mutacion = obtenerAleatorios(min = 0, max = solucion.size - 1,
                        num = num_mutations)
    
    for i in indices_mutacion
        s.mov(i,0.4) # Operador de mutación simple
    end
    
    return s
end

~~~

$\text{   }$


## Evolución Diferencial

La evolución diferencial es un algoritmo evolutivo en el que la población de soluciones avanza de acuerdo a las reglas de combinación que se muestran más adelante. Como algoritmo evolutivo, la estrategia de resolución se puede resumir en el siguiente pseudocódigo:

$\text{   }$

~~~ruby

# Genera soluciones uniformememnte
# distribuidas en [0,1]
iniciarPoblacionAleatoria()

while not condiciones_parada()
    nuevaGeneracion()
end

return poblacion.mejorSolucion()
~~~

$\text{   }$

Las condiciones de parada serán, en general, el número de evaluaciones de la función objetivo, aunque también podrían considerarse otras posibilidades, como el número de generaciones desarrolladas. El esquema de desarrollo de nuevas generaciones, para los distintos algoritmos de evolución diferencial, puede descomponerse en las siguientes fases:

$\text{   }$

~~~ruby

def nuevaGeneracion()
    seleccion()     # Selección de padres
    recombinacion() # Obtención de hijos
    reemplazo()     # Sustitución de la población
end
~~~

$\text{   }$

El proceso de selección consiste en extraer grupos de padres de la población. Se extraerán tres padres por cada individuo de la población, que serán los que intervengan posteriormente en las recombinaciones para cada hijo (el tercer padre podría no intervenir según el operador de cruce utilizado, pero por simplicidad se extrae siempre).

$\text{   }$

~~~ruby

def seleccion()
    for i from 1 to poblacion.size()
        [r1,r2,r3] = aleatoriosDistintosEntre(0,poblacion.size()-1)
        padres.añadir([poblacion[r1],poblacion[r2],poblacion[r3]])
    end
end
~~~

$\text{   }$

Para la recombinación, utilizaremos el operador de cruce correspondiente según el modelo de evolución diferencial escogido. En cada recombinación pueden intervenir hasta tres padres escogidos al azar en la población, además de la mejor solución de cada generación. La aleatoriedad con la que se escogieron los padres en el proceso de selección nos permite ahora recorrer la lista de padres e ir pasándoselos de tres en tres al operador de cruce.

$\text{   }$

~~~ruby
def cruce()
    for i from 0 to poblacion..size()-1
        hijos.añadir(operadorCruce(padres[3*i],padres[3*i+1],
                   padres[3*i+2],poblacion[i],mejor_solucion))
    end
end
~~~

$\text{   }$

A continuación, describimos ambos operadores de cruce. El cruce aleatorio obtiene como nueva solución a uno de los padres trasladado en la dirección de los otros dos un factor $F$, bajo la recombinación binomial, es decir, dicha recombinación tendrá lugar solo bajo cierta probabilidad $CR$ (por gen). Se han tomado $F=CR=0,5$. También hay que tener en cuenta que la recombinación podría exceder el intervalo $[0,1]$, por lo que puede ser necesario truncar.

$\text{   }$

~~~ruby
#pi: Padre i-ésimo
#x: Individuo i-ésimo de la población
#best: Mejor solución
def DE_Rand(p1,p2,p3,x,best)
    s=solucion(tam = p1.size())
    
    for k from 1 to solucion.size()
        if aleatorioUniforme(0,1) < CR  # Recombinación
            s[k] = p1[k] + F * (p2[k] - p3[k])
            if s[k] < 0.0 then s[k] = 0.0
            if s[k] > 0.0 then s[k] = 1.0
        else  # Mantenemos atributo
            s[k] = x[k]
        end
    end
end
~~~

$\text{   }$

EL cruce *Current-to-best* se obtiene de trasladar el individuo de la población, primero en la dirección hacia la mejor solución, y luego en la dirección entre los dos padres que intervienen en este caso, ambas una cantidad $F$. De nuevo consideramos recombinación binomial, con $F=CR=0,5$, y la necesidad de truncar si un atributo excede los límites.

$\text{   }$

~~~ruby
#pi: Padre i-ésimo
#x: Individuo i-ésimo de la población
#best: Mejor solución
def DE_Rand(p1,p2,p3,x,best)
    s=solucion(tam = p1.size())
    
    for k from 1 to solucion.size()
        if aleatorioUniforme(0,1) < CR  # Recombinación
            s[k] = x[k] + F * (best[k] - x[k]) + F*(p1[k]-p2[k])
            if s[k] < 0.0 then s[k] = 0.0
            if s[k] > 0.0 then s[k] = 1.0
        else  # Mantenemos atributo
            s[k] = x[k]
        end
    end
end
~~~

$\text{   }$

Finalmente, el esquema de reemplazamiento utilizado es uno a uno, es decir, para cada individuo de la población, se compara con el hijo obtenido en esa misma posición y en la siguiente generación se queda el mejor de los dos. En este momento también nos aseguramos de que se actualiza la mejor solución de la población.

$\text{   }$

~~~ruby

def reemplazo()
    for i from 1 to poblacion.size()
        if hijo[i].fitness > poblacion[i].fitness
            poblacion[i] = hijo[i]
            if hijo[i].fitness > mejorSolucion.fitness
                mejorSolucion = hijo[i]
            end
        end
    end
end
~~~

$\text{   }$

Por último, sobre las llamadas a la función objetivo, se realizan durante la fase de recombinación, tantas como hijos se hayan creado.


\clearpage

# Algoritmo de comparación: RELIEF

El algoritmo utilizado para comparar con las heurísticas es el greedy RELIEF, con algunas modificaciones para satisfacer las restricciones de la solución. Este algoritmo parte de un vector inicial de pesos inicializado a 0, y para cada dato en la partición, busca los datos más cercanos a él de su misma clase (amigo más cercano) y de clase distinta (enemigo más cercano), respectivamente. Después, actualiza el vector de pesos sumando las distancias componente a componente con el enemigo más cercano y restando las distancias componente a componente con el amigo más cercano. Con esto se pretende dar mayor relevancia a las características que mejor separan los datos de clases distintas, y disminuir la importancia de las características que separan datos de la misma clase. Una vez actualizado el vector con todos los datos, para satisfacer las restricciones de la solución, las componentes negativas se hacen cero y se normaliza el vector con la norma del máximo. El pseudocódigo queda como sigue:

$\text{   }$

~~~ruby

def RELIEF(particion)
    w = [0,...,0]
    for dato in particion
        amigo = amigoMasCercano(dato,particion)
        enemigo = enemigoMasCercano(dato,particion)
        
        for i from 1 to w.size()
            w[i] = w[i] - |dato[i] - amigo[i]| + |dato[i] - enemigo[i]| 
        end
    end
    
    if w[i] < 0 then w[i] = 0 for i from 1 to w.size
    
    normalizar_max(w)
    
    return(w)
    
end

~~~

$\text{   }$

Los algoritmos para el amigo y el enemigo más cercanos son análogos, con la única diferencia de que el amigo más cercano no puede compararse con el propio dato. A continuación se muestran los pseudocódigos:

$\text{   }$

~~~ruby
def amigoMasCercano(dato, particion)
    dist_mas_cercano = INF
    for elem in particion
        if elem != dato and elem.clase == dato.clase
            if dist(elem,dato) < dist_mas_cercano
                dist_mas_cercano = dist(elem,dato)
                amigo = elem
            end
        end
    end 
    
    return amigo
end

def enemigoMasCercano(dato, particion)
    dist_mas_cercano = INF
    for elem in particion
        if elem.clase != dato.clase
            if dist(elem,dato) < dist_mas_cercano
                dist_mas_cercano = dist(elem,dato)
                enemigo = elem
            end
        end
    end 
    
    return enemigo
end

~~~

$\text{   }$

\clearpage

# Procedimiento considerado para desarrollar la práctica

Para el desarrollo de los distintos algoritmos de la práctica se ha elaborado un código propio en `C++`. Para la lectura de los ficheros arff se ha incorporado y arreglado un código C++ disponible en GitHub [@arff]. Los códigos disponen de un `makefile` que permite compilar todos los módulos automáticamente y de varios scripts de bash para tomar resultados. El ejecutable generado es `./bin/apc`. Los distintos problemas se encuentran en la carpeta `data`.

Para ejecutar el programa desde la línea de comandos se utiliza la sintaxis `./bin/apc [archivo del problema] [opciones]`. Las opciones disponibles son:

- `-a <algoritmo>` (**Necesaria**). Especifica el algoritmo a utilizar. Los algoritmos disponibles son:

>- `1NN`: Evalua el clasificador 1NN. Por defecto, sobre una solución constante 1. Se puede especificar otra solución con la opción `-w`.
>- `RANDOM`: Genera y evalúa soluciones aleatorias uniformemente distribuidas sobre [0,1].
>- `RELIEF`: Obtiene soluciones con el algoritmo RELIEF.
>- `RANDOM+LS`: Aplica la búsqueda local sobre soluciones iniciales aleatorias.
>- `RELIEF+LS`: Aplica la búsqueda local sobre soluciones iniciales RELIEF.
>- `AGG-BLX`: Obtiene soluciones con el AGG con operador de cruce BLX-0.3.
>- `AGG-CA`: Obtiene soluciones con el AGG con operador de cruce aritmético.
>- `AGE-BLX`: Obtiene soluciones con el AGE con operador de cruce BLX-0.3.
>- `AGE-BLX`: Obtiene soluciones con el AGE con operador de cruce aritmético.
>- `AM-10-1.0`: Algoritmo memético que aplica BL a todos los individuos cada 10 generaciones.
>- `AM-10-0.1`: Algoritmo memético que aplica BL a un 10 % de la población al azar cada 10 generaciones.
>- `AM-10-0.1mej`: Algoritmo memético que aplica BL al 10 % mejor de la población cada 10 generaciones.
>- `SA`: Enfriamiento simulado con esquema de Cauchy,
>- `ILS`: Obtiene soluciones con Búsqueda Local Reiterada.
>- `DE-RAND`: Algoritmo de evolución diferencial con cruce `Rand`.
>- `DE-CURRENTTOBEST`: Algoritmo de evolución diferencial con cruce `Current-To-Best`.

- `-m <modo>`: Modo de evaluación y particionado. Por defecto, `5FOLD`. Los modos disponibles son:

>- `5x2`: Evaluación con `1NN` y validación cruzada `5x2` (práctica 1).
>- `5FOLD`: Evaluación media de `1NN` y reducción, con validación cruzada 5-Fold (práctica 2).

- `-o <nombre salida>`: Especifica un nombre para los ficheros de salida con resultados que se crearán. Es necesario para utilizar las opciones `-p` y `-t`. Dependiendo de estas opciones, se crearán distintos ficheros con el nombre indicado y distintas extensiones añadidas por el programa.

- `-p <string>`: Indica qué datos serán imprimidos en ficheros. Cada carácter en `string` indica un tipo de dato a imprimir. Los datos admitidos son:

>- `f`: Se imprimirá un archivo con los fitness obtenidos (`.fit`).
>- `p`: Se imprimirá un archivo con los índices de cada partición utilizada (`.part`).
>- `t`: Se imprimirá un archivo con los tiempos obtenidos (`.time`).
>- `i`: Se imprimirá un archivo con los fitness obtenidos sobre la partición de entrenamiento (`.trfit`).
>- `s`: Se imprimirá un archivo con las soluciones obtenidas (`.sol`).

- `-s <semilla>`: Especifica una semilla para generar números aleatorios con la que ejecutar el programa.

- `-t <string>`: Se creará una tabla (`.table`) con los datos indicados en `string`. Cada carácter en `string` indica un tipo de dato a imprimir. Los datos admitidos son los mismos que en la opción `-p`, a excepción de `s` y `p`.

- `-w <fichero solucion>`: Especifica un fichero donde hay almacenada una solución para clasificar con ella. Solo se tendrá en cuenta si el algoritmo es 1NN.


En la práctica, el uso del programa se reduce a la llamada `./bin/apc <nombre problema> -a <algoritmo> -s <semilla>`. Un ejemplo de uso del programa para tomar resultados es `./bin/apc ./data/sonar.arff -a RELIEF -s 3 -o ./sol/RELIEF_sonar_3 -t fti -p sp`.

Finalmente, se proporcionan los siguientes scripts de bash:

- `./sh/exec.sh`. Dado un directorio, pasado como argumento, ejecuta todos los algoritmos con todos los problemas y guarda los resultados en el directorio. Se puede modificar para ejecutar solo determinados problemas con determinados algoritmos, y para las semillas que se deseen.

- `./sh/calcAvg.sh`. Dado un directorio, pasado como argumento, lee las soluciones encontradas en ese directorio y genera ficheros con las tablas de datos medios obtenidos para cada algoritmo en cada problema. Los ficheros resultantes tienen la forma `means_$SEMILLA.table`.

- `./sh/start.sh`. Genera un nuevo directorio basado en la fecha de la ejecución y llama a los dos scripts anteriores para tomar resultados.

\clearpage

# Experimentos y análisis de resultados

## Resultados obtenidos.

Todas las ejecuciones que se muestran de ahora en adelante se han realizado sobre un ordenador HP con las siguientes características:

- Procesador Intel(R) Core(TM) i7
- Frecuencia del procesador: 2.8 GHz
- 4 procesadores principales, 8 procesadores lógicos
- 16 GB de RAM.

Las ejecuciones se han realizado sobre el sistema operativo Windows 7, a través de la herramienta `Cygwin` [@cygwin], que proporciona funcionalidades para Windows similares a las de las distribuciones de Linux. Finamente, el código `C++` utilizado ha sido compilado con optimización `-O2`.

Para la toma de resultados se ha utilizado el script `start.sh` mencionado en la sección anterior, y la semilla utilizada ha sido $3141592$.

Para cada problema y cada algoritmo se han tomado los siguientes datos: fitness sobre la muestra de entrenamiento, fitness sobre los datos test, tasas de clasificación y reducción sobre el test y tiempo de ejecución. Los resultados obtenidos son:

\begin{figure}[H]
\centering
\includegraphics[width=15 cm]{./images/1NN.png}
\caption{Resultados de la ejecución del clasificador 1NN con pesos 1.\label{fig:1NN}}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=15 cm]{./images/RANDOM.png}
\caption{Resultados de la ejecución del clasificador 1NN con soluciones aleatorias.\label{fig:RANDOM}}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=15 cm]{./images/RANDOM+LS.png}
\caption{Resultados de la ejecución de la búsqueda local partiendo de soluciones aleatorias.\label{fig:RANDOMLS}}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=15 cm]{./images/RELIEF.png}
\caption{Resultados de la ejecución del greedy RELIEF.\label{fig:RELIEF}}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=15 cm]{./images/RELIEF+LS.png}
\caption{Resultados de la ejecución de la búsqueda local partiendo de soluciones RELIEF.\label{fig:RELIEFLS}}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=15 cm]{./images/AGG-BLX.png}
\caption{Resultados de la ejecución del algoritmo AGG-BLX.\label{fig:AGGBLX}}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=15 cm]{./images/AGG-CA.png}
\caption{Resultados de la ejecución del algoritmo AGG-CA.\label{fig:AGGCA}}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=15 cm]{./images/AGE-BLX.png}
\caption{Resultados de la ejecución del algoritmo AGE-BLX.\label{fig:AGEBLX}}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=15 cm]{./images/AGE-CA.png}
\caption{Resultados de la ejecución del algoritmo AGE-CA.\label{fig:AGECA}}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=15 cm]{./images/AM-10-1.png}
\caption{Resultados de la ejecución del algoritmo AM-10-1.0.\label{fig:AM101}}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=15 cm]{./images/AM-10-01.png}
\caption{Resultados de la ejecución del algoritmo AM-10-0.1.\label{fig:AM1001}}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=15 cm]{./images/AM-10-01mej.png}
\caption{Resultados de la ejecución del algoritmo AM-10-0.1mej.\label{fig:AM1001mej}}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=15 cm]{./images/global_table.png}
\caption{Resultados medios y comparación conjunta de todos los algoritmos.\label{fig:allalgs}}
\end{figure}

## Valoración general de los resultados.

En primer lugar discutimos las diferencias en lo respectivo al aprendizaje con el modelo de validación de la práctica anterior. En esta ocasión si se aprecian variaciones mayores entre los distintos modelos en lo que respecta a las tasas sobre los datos test. Además, estas tasas, en general, son parecidas a las obtenidas sobre los datos de entrenamiento. Podemos concluir que se ha conseguido reducir el sobreaprendizaje. Esto se debe en parte a que el modelo de validación 5-Fold presenta menos varianza que las particiones al 50 % realizadas con 5x2, y en parte también a que la tasa de reducción influye bastante y permite eliminar muchas características, en general, haciendo que el clasificador aprenda con menos características y en consecuencia reduciendo la capacidad de ajuste a los datos. Aun así, en los algoritmos que consiguen alcanzar valores por encima del 85-90 \% sobre la muestra de entrenamiento, se aprecia (sobre todo en `sonar`) que las evaluaciones de los datos test no consiguen subir tanto, quedándose estancadas en torno al 80-83 \%. Es decir, se sigue produciendo algo de sobreaprendizaje, especialmente en `sonar`, que tienen menor número de datos que los otros dos problemas. De hecho, comparando las diferencias en las tasas de clasificación las diferencias son aún mayores (las tasas de clasificación sobre train no se muestran por espacio, pero como la tasa de reducción es fija, se puede deducir como $clas\_train = 2\cdot train\_fit - tasa\_red$). En este caso, en sonar vemos que, por ejemplo, en enfriamiento simulado, la tasa de clasificación en train supera el 94 \%, quedándose en 80 \% en test. Con ILS y evolución diferencial ocurre igual. En `spambase` estos mismos algoritmos también reducen la tasa de clasificación sobre test, pero las diferencias no son tan abultadas.

En cuanto a los conjuntos de datos, podemos sacar las mismas conclusiones que en la práctica anterior. Se observa que el conjunto que mejores resultados da es `wdbc`. Los otros dos proporcionan resultados similares, y bastante inferiores. Esto puede deberse al menor número de características en `wdbc` en parte, y también a que el origen de los distitntos conjuntos de datos puede producir más o menos ruidos. Por ejemplo, en `sonar` los datos clasificados se obtienen mediante señales obtenidas sobre distintos materiales, y estos pueden verse afectados por numerosas condiciones externas. En `spambase` puede introducirse un ruido similar, ya que un mismo correo podría considerarse spam o no según el destinatario. En `wdbc` puede haber menos ruido debido a que los datos se toman de imágenes de células, en las que en principio puede ser menos conflicitvo medir sus características.

En lo relativo a los tiempos, el algoritmo greedy sigue siendo el más rápido, como era de esperar, y el tiempo obtenido por el clasificador greedy nos da una medida del tiempo que tarda en evaluarse cada llamada a la función objetivo. Fijadas las 15000 iteraciones que utilizan los distintos algoritmos, vemos que, salvo búsqueda local y enfriamiento simulado, el resto requieren de tiempos parecidos para evaluarse, y esto es debido a que prácticamente todo el tiempo de estos algoritmos es consumido evaluando la función objetivo. La búsqueda local tarda menos tiempo porque termina antes de las 15000 iteraciones por el criterio de vecinos encontrados sin éxito. En cambio, el enfriamiento simulado termina antes porque el criterio de enfriamiento acepta muchas soluciones, y el algoritmo termina alcanzando la temperatura final algo antes de las 15000 iteraciones, con el esquema de Cauchy. Por otra parte, al añadir al criterio de aceptación la condición de ignorar soluciones que no han variado su coste, el número de evaluaciones realizadas no es en ninguno de los problemas menor que la mitad del esperado. Sin esta condición se aceptan muchas más soluciones, haciendo que en `sonar, por ejemplo, apenas se tarden 2 segundos.

Finalmente, en cuanto a la capacidad de aprendizaje de cada algoritmo, vemos que, en general, las tasas de clasificación del RELIEF y el 1NN ya son elevadas de por sí, y solo algunos algoritmos la superan ligeramente, según el problema. Sin embargo, apenas consiguen reducción. Esto es obvio para el 1NN y, en el caso del RELIEF, es un algoritmo determinista y que no está ideado para reducir, luego su tasa de reducción es muy baja. La poca diferencia entre estos dos algoritmos y los demás en cuanto a clasificación nos indica que los algoritmos heurísticos se centran sobre todo en aumentar la tasa de reducción. Vemos que, salvo `DE-RAND`, los algoritmos no evolutivos `ILS` y `SA` son los que consiguen mayores reducciones. Esto puede deberse a que implícitamente tienen una componente de búsqueda local, luego los resultados que consiguen son al menos los de la búsqueda local, y estos resultados superan en reducción a los evolutivos salvo `DE-RAND`. El memético se encuentra en esta misma situación, aunque sin llegar a los resultados de `ILS` y `SA`. Finalmente, el que claramente consigue reducir más es la evolución diferencial con cruce aleatorio, aunque también suele clasificar ligeramente peor a los demás sobre el test. Aunque en tasas de clasificación hay pocas diferencias y los resultados varían con el problema. En agregado, `DE-RAND` proporciona mejores resultados en todos los problemas gracias a su reducción.

En los siguientes análisis, si no se indica lo contrario, todas las ejecuciones realizadas han sido sobre el problema `sonar` con la semilla `3141592`.

## Análisis de la evolución del enfriamiento simulado.

Lo que distingue al enfriamieno simulado de los demás algoritmos es su capacidad de poder ir aceptando soluciones peores a la actual sobre las que seguir trabajando. También este número de aceptaciones disminuye conforme se avanza en el algoritmo (va disminuyendo la temperatura). Esto se puede observar gráficamente. En la siguiente gráfica se muestra la evolución de las tasas de la solución que va modificando el algoritmo (en esta gráfica y en las sucesivas, en rojo se muestra la tasa de clasificación, en azul la de reducción y en morado el agregado durante el aprendizaje, es decir, sobre el train).



```{r, echo=F,warning=F}
# Gráfica fitness / iteraciones SA

fit_SA <- read.table("./data/evol_SA.apc")

plot(fit_SA[,1],fit_SA[,4],type="l",col="purple",xlab = "Iteraciones",ylab = "Fitness",ylim = c(10,100))
points(fit_SA[,1],fit_SA[,2],type="l",col="red")
points(fit_SA[,1],fit_SA[,3],type="l",col="blue")
#points(fit_SA[,1],fit_SA[,5],type="l",col="gold")


```

\begin{figure}[H]
\centering
\caption{Evolución de la función objetivo en función del número de iteraciones en enfriamiento simulado.\label{fig:evosa}}
\end{figure}

Vemos como, durante las primeras iteraciones, se aprecian muchas subidas y bajadas en el agregado. La diferencia en estas subidas y bajadas se va suavizando conforma avanzan las iteraciones, hasta que se acaba estabilizando en las iteraciones finales, cuando ya la temperatura es muy baja. También vemos que bajadas grandes luego permiten subir una mayor cantidad, lo que justifica el uso de este algoritmo: aceptar soluciones peores para poder explorar distintas zonas del espacion de búsqueda y evitar óptimos locales. También se observa que, aunque se estabilice el agregado por el final, las otras tasas sí que presentan alguna variación importante, pero lo que se está optimizando es el agregado, así que es algo razonable.

También podemos ver que, mientras que la tasa de clasificación apenas varía en un pequeño intervalo, la tasa de reducción sube una gran cantidad a lo largo del algoritmo. Esto se puede apreciar en todas las gráficas que se verán más adelante, lo que nos confirma que los algoritmos heurísticos se centran en aumentar la reducción.

## Análisis de la evolución en ILS

La principal característica del ILS es que, cada cierto número de iteraciones, la solución con la que se trabaja es mutada con un cambio brusco. Mientras, el resto del tiempo se está haciendo búsqueda local. El cambio brusco es el que nos permite explorar nuevas zonas en el espacio de búsqueda, y a priori no nos garantizan que mejoren la solución actual. De hecho, lo normal es que no ocurra, pero la búsqueda local sobre esta nueva solución nos puede conducir a mejores soluciones en zonas distintas del espacio de búsqueda. En la siguiente gráfica se muestra la evolución del ILS a lo largo del número de iteraciones.

```{r, echo=F,warning=F}
# Gráfica fitness / iteraciones ILS

fit_ILS <- read.table("./data/evol_ILS.apc")

maxs_ILS <- c()
for(i in 1:nrow(fit_ILS)){
  maxs_ILS <- c(maxs_ILS,max(fit_ILS[1:i,4]))
}

plot(fit_ILS[,1],maxs_ILS,type="l",col="gold",xlab = "Iteraciones",ylab = "Fitness",ylim = c(10,100))
points(fit_ILS[,1],fit_ILS[,2],type="l",col="red")
points(fit_ILS[,1],fit_ILS[,3],type="l",col="blue")
points(fit_ILS[,1],fit_ILS[,4],type="l",col="purple")


```

\begin{figure}[H]
\centering
\caption{Evolución de la función objetivo en función del número de iteraciones en ILS\label{fig:evoils}}
\end{figure}

Se aprecia claramente el comportamiento que habíamos indicado. el algoritmo va aplicando búsqueda local, que va aumentando el valor de la función objetivo, pero cada cierto número de iteraciones hay una bajada. Esta se debe a la mutación brusca. En ocasiones, la búsqueda local sobre la mutación no consigue mejorar la solución actual, por lo que se vuelve a ella y se prueba con otra mutación, pero otras veces sí consigue superar el valor de la solución anterior (marcado en amarillo), y obteniendo así una nueva solución más prometedora sobre la que trabajar.

## Análisis de la evolución diferencial.

En las siguientes gráficas se muestra la evolución de las tasas en función de las generaciones en ambos algoritmos de evolución diferencial. Se observa que con la recombinación `RAND` hay una gran subida de reducción y se aprecia mucha variabilidad hasta casi el final del algoritmo, mientras que en `CurrentToBest` la solución se estabiliza enseguida.

```{r, echo=F,warning=F}
# Gráfica fitness / Generación DE-RAND

fit_DERAND <- read.table("./data/evol_DERAND.apc")

plot(fit_DERAND[,1],fit_DERAND[,4],type="l",col="purple",xlab = "Generaciones",ylab = "Fitness",ylim = c(10,100))
points(fit_DERAND[,1],fit_DERAND[,2],type="l",col="red")
points(fit_DERAND[,1],fit_DERAND[,3],type="l",col="blue")

```

\begin{figure}[H]
\centering
\caption{Evolución de la función objetivo en función del número de generaciones en DE-RAND\label{fig:evoderand}}
\end{figure}

```{r, echo=F,warning=F}

# Gráfica fitness / generación DE-CTB

fit_DECTB <- read.table("./data/evol_DECTB.apc")

plot(fit_DECTB[,1],fit_DECTB[,4],type="l",col="purple",xlab = "Generaciones",ylab = "Fitness",ylim = c(10,100))
points(fit_DECTB[,1],fit_DECTB[,2],type="l",col="red")
points(fit_DECTB[,1],fit_DECTB[,3],type="l",col="blue")

```

\begin{figure}[H]
\centering
\caption{Evolución de la función objetivo en función del número de generaciones en DE-CurrentToBest\label{fig:evodectb}}
\end{figure}

### Comparación de los operadores de recombinación

Para estudiar las diferencias entre ambos algoritmos de evolución diferencial, estudiamos lo que realmente los distingue, el operador de recombinación. Para ello, ejecutamos el algoritmo de evolución diferencial y miramos cómo evoluciona la mejor solución en cada generación. En las siguientes gráficas se muestran, por superposición y por separado, la evolución de las mejores soluciones con el paso de las generaciones en `DE-RAND` (se muestra solo un número pequeño de mejoras, para que sea representable).

```{r, echo=F,warning=F}

# Cruce RAND superposición

sols <- read.table("./data/evosols_DERAND.sol")
sols_mat_derand <- as.vector(sols[,1:60])
sols_mat_derand [sols_mat_derand<0.1] = 0
colors <- heat.colors(nrow(sols_mat_derand))
colors <- colors[length(colors):1]

inds <- seq(ncol(sols_mat_derand))
inds_prev <- seq(ncol(sols_mat_derand)-1)
inds_next <- inds_prev + 1

plot(-100, xlab = "Características", ylab = "Peso", xlim = c(1,60), ylim = c(0,1))
for(i in seq(from = 1, to = nrow(sols_mat_derand),length.out = 8)){
  w <- as.numeric(sols_mat_derand[i,])
  segments(x0 = inds[inds_prev], y0 = w[inds_prev], x1 = inds[inds_next], y1 = w[inds_next], col = colors[i])
  points( x = inds, y = w, col = colors[i])
}

```

\begin{figure}[H]
\centering
\caption{Evolución superpuesta de las mejores soluciones con el operador de cruce RAND en evolución diferencial (los colores más cálidos representan soluciones más evolucionadas).\label{fig:randevo1}}
\end{figure}

```{r, echo=F,warning=F}
# Cruce RAND por separado
par(mfrow = c(1,2))
for(i in seq(from = 1, to = nrow(sols_mat_derand),length.out = 8)){
  barplot(as.numeric(sols_mat_derand[i,]), col = colors[i])
}
par(mfrow = c(1,1))

```

\begin{figure}[H]
\centering
\caption{Evolución de las mejores soluciones con el operador de cruce RAND en evolución diferencial.\label{fig:randevo2}}
\end{figure}

En la gráfica de soluciones superpuestas vemos cómo hay una gran variabilidad en las mejores soluciones que se van obteniendo. Esto se debe a que en este algoritmo el cruce se basa en padres escogidos completamente al azar entre la población, por lo que la componente aleatoria es importante. También el gran número de cambios muestra que esta forma de recombinación, a pesar de ser aleatoria es muy efectiva, y además reduce enormemente los pesos, como se observa en la segunda gráfica.

A continuación realizamos el mismo proceso con `DE-CurrentToBest`.

```{r, echo=F,warning=F}

# Cruce CTB superposición
sols <- read.table("./data/evosols_DECTB.sol")
sols_mat_dectb <- as.vector(sols[,1:60])
sols_mat_dectb [sols_mat_dectb<0.1] = 0
colors <- heat.colors(nrow(sols_mat_dectb))
colors <- colors[length(colors):1]

inds <- seq(ncol(sols_mat_dectb))
inds_prev <- seq(ncol(sols_mat_dectb)-1)
inds_next <- inds_prev + 1

plot(-100, xlab = "Características", ylab = "Peso", xlim = c(1,60), ylim = c(0,1))
for(i in seq(from = 1, to = nrow(sols_mat_dectb),length.out = 8 )){
  w <- as.numeric(sols_mat_dectb[i,])
  segments(x0 = inds[inds_prev], y0 = w[inds_prev], x1 = inds[inds_next], y1 = w[inds_next], col = colors[i])
  points( x = inds, y = w, col = colors[i])
}

```

\begin{figure}[H]
\centering
\caption{Evolución de las mejores soluciones superpuestas con el operador de cruce CurrentToBest en evolución diferencial (los colores más cálidos representan soluciones más evolucionadas)\label{fig:ctbevo1}}
\end{figure}

```{r, echo=F,warning=F}

# Cruce CTB separado
par(mfrow = c(1,2))
for(i in seq(from = 1, to = nrow(sols_mat_dectb),length.out = 8)){
  barplot(as.numeric(sols_mat_derand[i,]), col = colors[i])
}
par(mfrow = c(1,1))

```
\begin{figure}[H]
\centering
\caption{Evolución de las mejores soluciones superpuestas con el operador de cruce CurrentToBest en evolución diferencial\label{fig:ctbevo2}}
\end{figure}

En este caso vemos en la gráfica de soluciones superpuestas que los pesos se mueven mucho menos y tienden a estabilizarse en torno a una solución. Esto puede deberse a que en este caso, aunque también influye el movimiento de padres escogidoa al azar, el operador de cruce tiene una componente no aleatoria que tiende a mover las soluciones en la dirección de la mejor solución. De esta forma, la variabilidad es menor. Además, también disminuye bastante la reducción de pesos porque el acercamiento a la mejor solución, que inicialmente no suele tener pesos bajos, dificulta que los pesos en los hijos puedan bajar.

### Evolución de una población completa en DE-RAND

A continuación vamos a ver cómo evoluciona una población de individuos mediante la evolución diferencial con el cruce `RAND`. Para ello, ejecutamos el algoritmo con una población de 10 individuos y vemos cómo evolucionan sus tasas con el número de generaciones. El menor número de individuos impide que se alcancen las mismas tasas que con 50, pero aun así se puede apreciar la tendencia evolutiva de la población.

```{r, echo = F, warning = F}

cr <- matrix( nrow = 1500, ncol = 31)

colors <- c("red","blue","yellow","green","purple","cyan","black","pink","brown","gray")

cr[,1] <- seq(nrow(cr))
for(i in 1:10){
    sols <- read.table(paste("./data/DE_sol",sep = "",i-1,".sol"))
    cr[,-1+c(3*i,3*i+1,3*i+2)] <- as.matrix(sols[,c(2,3,4)])
}

plot(-100,xlab = "Generaciones", ylab = "Fitness", xlim = c(0,100), ylim = c(40,90))
for(i in 1:10){
    points(x = cr[,1], y = cr[,3*i+1], col = colors[i], pch = 16,type="l")
    #segments(x0 = gens[inds_prev], y0 = cr[inds_prev,i], x1 = gens[inds_next], y1 = cr[inds_next,i], col = colors[i])
}

plot(-100,xlab = "Generaciones", ylab = "Tasa Reducción", xlim = c(0,100), ylim = c(20,80))
for(i in 1:10){
    points(x = cr[,1], y = cr[,3*i], col = colors[i], pch = 16,type="l")
    #segments(x0 = gens[inds_prev], y0 = cr[inds_prev,i], x1 = gens[inds_next], y1 = cr[inds_next,i], col = colors[i])
}

plot(-100,xlab = "Generaciones", ylab = "Tasa Clasificación", xlim = c(0,100), ylim = c(70,100))
for(i in 1:10){
    points(x = cr[,1], y = cr[,3*i-1], col = colors[i], pch = 16,type="l")
    #segments(x0 = gens[inds_prev], y0 = cr[inds_prev,i], x1 = gens[inds_next], y1 = cr[inds_next,i], col = colors[i])
}


```

\begin{figure}[H]
\centering
\caption{Evolución de fitness, tasa de clasificación y tasa de reducción en DE-RAND para una población de 10 individuos. Cada color representa a un individuo.\label{fig:derandpoblacion}}
\end{figure}

Podemos apreciar claramente en primer lugar, en la gráfica de fitness, el elitismo del algoritmo y el reemplazamiento uno a uno. Como consecuencia del reeemplazamiento uno a uno, cada individuo nunca va a empeorar su solución, luego todos los fitness son funciones crecientes. Además, esto nos asegura el elitismo, ya que la mejor solución siempre se va a mantener, salvo que sea reemplazada por una solución mejor.

En las tasas de clasificación y reducción no se puede decir lo mismo, y es que a veces las soluciones bajan su valor en estas gráficas o incluso se pierde el mejor valor para una de las tasas. Pero como lo que el algoritmo optimiza el agregado de las tasas, estas bajadas implican una subida en la tasa complementaria, y esto permite conservar el crecimiento constante de la función objetivo. También vemos que las tasas de clasificación oscilan en torno a los mismos valores a lo largo del algoritmo, mientras que las de reducción suben bastante rápido, como ha estado ocurriendo a lo largo de los distintos algoritmos heurísticos. 

## Evolución de los algoritmos de la práctica 1

Finalmente analizamos los dos algoritmos genéticos incorporados de la práctica 1.

```{r, echo=F,warning=F}

# Gráfica fitness / generación AM

fit_DECTB <- read.table("./data/evol_AGG.apc")

plot(fit_DECTB[,1],fit_DECTB[,4],type="l",col="purple",xlab = "Generaciones",ylab = "Fitness",ylim = c(10,100))
points(fit_DECTB[,1],fit_DECTB[,2],type="l",col="red")
points(fit_DECTB[,1],fit_DECTB[,3],type="l",col="blue")

```

\begin{figure}[H]
\centering
\caption{Evolución de la función objetivo en función del número de generaciones en AGG-BLX\label{fig:evoderand}}
\end{figure}

```{r, echo=F,warning=F}

# Gráfica fitness / generación AM

fit_DECTB <- read.table("./data/evol_AM.apc")

plot(fit_DECTB[,1],fit_DECTB[,4],type="l",col="purple",xlab = "Generaciones",ylab = "Fitness",ylim = c(10,100))
points(fit_DECTB[,1],fit_DECTB[,2],type="l",col="red")
points(fit_DECTB[,1],fit_DECTB[,3],type="l",col="blue")

```

\begin{figure}[H]
\centering
\caption{Evolución de la función objetivo en función del número de generaciones en AM-10-0.1mej\label{fig:evoderand}}
\end{figure}

En el caso del AGG-BLX podemos observar un crecimiento lento pero constante, principalmente debido a la reducción. El operador de cruce BLX favorece la diversificación y en consecuencia va permitiendo el aumento de reducciones siempre que sigan manteniendo una buena tasa de clasificación, lo que permite este crecimiento pausado.

En cuanto al algoritmo memético, se aprecia un comportamiento similar al del AGG, pero con algunos saltos más marcados, sobre todo al principio, debidos posiblemente a que en las generaciones de búsqueda local la solución a la que se le ha aplicado dicha búsqueda ha conseguido dar un salto de calidad.
